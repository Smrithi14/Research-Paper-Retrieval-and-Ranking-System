{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and tokenize titles\n",
    "def tokenize_title(title):\n",
    "    return set(re.sub(r\"[^\\w\\s]\", \"\", title.lower()).split())\n",
    "\n",
    "# Function to check word match percentage\n",
    "def is_match(input_title, paper_title, threshold=10):\n",
    "    input_tokens = tokenize_title(input_title)\n",
    "    paper_tokens = tokenize_title(paper_title)\n",
    "    \n",
    "    common_words = input_tokens.intersection(paper_tokens)\n",
    "    match_percentage = (len(common_words) / len(input_tokens)) * 100 if input_tokens else 0\n",
    "    \n",
    "    return match_percentage >= threshold, match_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(search_query):\n",
    "    print(f\"\\nðŸ”¶ Supervisor Agent: Managing Research on '{search_query}'...\")\n",
    "    \n",
    "    papers = generation_agent(search_query)\n",
    "    feasible_papers = reflection_agent(papers, search_query)\n",
    "    ranked_papers = ranking_agent(feasible_papers)\n",
    "    improved_papers = evolution_agent(ranked_papers)\n",
    "    final_paper = proximity_agent(improved_papers)\n",
    "    \n",
    "    meta_review_agent()\n",
    "    \n",
    "    print(\"\\nâœ… Final Optimized Paper:\", final_paper)\n",
    "    return final_paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "def generation_agent(search_query):\n",
    "    print(f\"\\nðŸ”¹ Generation Agent: Fetching Papers for '{search_query}'...\")\n",
    "\n",
    "    # Setup Selenium with random user-agent to avoid bot detection\n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\"\n",
    "    ]\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--log-level=3\")  \n",
    "    options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # List of academic websites\n",
    "    websites = {\n",
    "        \"Google Scholar\": {\n",
    "            \"url\": f\"https://scholar.google.com/scholar?q={search_query.replace(' ', '+')}\",\n",
    "            \"title_xpath\": \"//h3[@class='gs_rt']/a\",\n",
    "            \"link_xpath\": \"//h3[@class='gs_rt']/a\",\n",
    "        },\n",
    "        \"CORE (Research Papers)\": {\n",
    "            \"url\": f\"https://core.ac.uk/search?q={search_query.replace(' ', '+')}\",\n",
    "            \"title_xpath\": \"//div[contains(@class, 'search-result')]//h3/a\",\n",
    "            \"link_xpath\": \"//div[contains(@class, 'search-result')]//h3/a\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for site, details in websites.items():\n",
    "        print(f\"ðŸ” Searching: {site}...\")\n",
    "\n",
    "        driver.get(details[\"url\"])\n",
    "        time.sleep(10)  # Increased wait time for JavaScript-heavy pages\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.XPATH, details[\"title_xpath\"]))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(f\"âš ï¸ Timeout on {site}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # âœ… Fetch the number of papers dynamically\n",
    "        total_papers = min(len(driver.find_elements(By.XPATH, details[\"title_xpath\"])),\n",
    "                           len(driver.find_elements(By.XPATH, details[\"link_xpath\"])))\n",
    "\n",
    "        if total_papers == 0:\n",
    "            print(f\"âš ï¸ No results found for {site}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"âœ… Extracted {total_papers} papers from {site}.\")\n",
    "\n",
    "        for i in range(total_papers):\n",
    "            try:\n",
    "                # âœ… Fix: Fetch fresh elements dynamically in each loop iteration\n",
    "                title_element = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, details[\"title_xpath\"]))\n",
    "                )\n",
    "                link_element = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, details[\"link_xpath\"]))\n",
    "                )\n",
    "\n",
    "                title_text = title_element.text.strip() if title_element else \"Title not found\"\n",
    "                link = link_element.get_attribute(\"href\") if link_element else \"No link available\"\n",
    "\n",
    "                # Fix CORE relative links\n",
    "                if site == \"CORE (Research Papers)\" and link.startswith(\"/display/\"):\n",
    "                    link = \"https://core.ac.uk\" + link\n",
    "\n",
    "                abstract_text = \"Abstract not found\"\n",
    "\n",
    "                # âœ… Visit each paper's link to fetch full abstract\n",
    "                if link != \"No link available\":\n",
    "                    try:\n",
    "                        driver.get(link)\n",
    "                        time.sleep(5)  # Wait for page load\n",
    "\n",
    "                        # âœ… Locate and extract abstract (Different websites have different structures)\n",
    "                        if \"core.ac.uk\" in link:\n",
    "                            abstract_xpath = \"//div[contains(@class, 'abstract')]\"\n",
    "                        elif \"ncbi.nlm.nih.gov\" in link:\n",
    "                            abstract_xpath = \"//div[@class='abstr']//p\"\n",
    "                        elif \"journals.aps.org\" in link:  # Example for APS journal\n",
    "                            abstract_xpath = \"//div[@class='abstract']/p\"\n",
    "                        else:\n",
    "                            abstract_xpath = \"//p[contains(text(), 'Abstract') or contains(text(), 'abstract')]\"\n",
    "\n",
    "                        try:\n",
    "                            abstract_element = WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.XPATH, abstract_xpath))\n",
    "                            )\n",
    "                            abstract_text = abstract_element.text.strip()\n",
    "                        except (NoSuchElementException, TimeoutException):\n",
    "                            print(f\"âš ï¸ No abstract found on {link}, skipping...\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ Error loading page {link}: {e}\")\n",
    "\n",
    "                # âœ… Skip papers without abstracts\n",
    "                if abstract_text == \"Abstract not found\":\n",
    "                    print(f\"âš ï¸ Skipping {title_text} (No abstract)\")\n",
    "                    continue  # Skip this paper\n",
    "\n",
    "                # âœ… Store the data in JSON format\n",
    "                data_list.append({\n",
    "                    \"site\": site,\n",
    "                    \"title\": title_text,\n",
    "                    \"link\": link,\n",
    "                    \"abstract\": abstract_text\n",
    "                })\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                print(f\"âš ï¸ Stale element detected, refetching elements...\")\n",
    "                continue  # Skip this iteration and retry with fresh elements\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    # âœ… Save data to a JSON file\n",
    "    json_filename = \"scraped_papers.json\"\n",
    "    with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data_list, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nðŸ“ Data saved successfully in {json_filename}!\")\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_agent(papers, search_query):\n",
    "    print(\"\\nðŸ”¹ Reflection Agent: Filtering Relevant Papers...\")\n",
    "    \n",
    "    filtered_papers = [paper for paper in papers if is_match(search_query, paper[\"title\"])[0]]\n",
    "    \n",
    "    print(\"âœ… Feasible Papers:\", len(filtered_papers))\n",
    "    return filtered_papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_agent(papers):\n",
    "    print(\"\\nðŸ”¹ Ranking Agent: Scoring Papers...\")\n",
    "    \n",
    "    ranked_papers = sorted(papers, key=lambda x: random.randint(1, 100), reverse=True)\n",
    "    \n",
    "    print(\"ðŸ† Top Ranked Paper:\", ranked_papers[0] if ranked_papers else \"No papers found\")\n",
    "    return ranked_papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution_agent(papers):\n",
    "    print(\"\\nðŸ”¹ Evolution Agent: Enhancing Selection...\")\n",
    "    \n",
    "    improved_papers = [paper for paper in papers if \"Review\" in paper[\"title\"] or \"Survey\" in paper[\"title\"]]\n",
    "    \n",
    "    print(\"ðŸš€ Improved Selection:\", improved_papers)\n",
    "    return improved_papers if improved_papers else papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximity_agent(papers):\n",
    "    print(\"\\nðŸ”¹ Proximity Agent: Checking Past Research Similarity...\")\n",
    "    \n",
    "    past_research = [\"AI Chatbots\", \"Self-Driving Cars\", \"Smart Homes\"]\n",
    "    best_paper = papers[0] if papers else None\n",
    "\n",
    "    if best_paper and any(topic in best_paper[\"title\"] for topic in past_research):\n",
    "        print(\"âš ï¸ Paper is similar to past research!\")\n",
    "    \n",
    "    return best_paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_review_agent():\n",
    "    print(\"\\nðŸ”¹ Meta-Review Agent: Final Performance Check...\")\n",
    "    \n",
    "    print(\"ðŸ“Š Papers Processed: âœ… Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¶ Supervisor Agent: Managing Research on 'quantum learning'...\n",
      "\n",
      "ðŸ”¹ Generation Agent: Fetching Papers for 'quantum learning'...\n",
      "ðŸ” Searching: Google Scholar...\n",
      "âœ… Extracted 10 papers from Google Scholar.\n",
      "âš ï¸ No abstract found on https://www.researchgate.net/profile/Ron-Chrisley/publication/305848278_Quantum_Learning/links/57a3736408aefe6167a5cf5c/Quantum-Learning.pdf, skipping...\n",
      "âš ï¸ Skipping Quantum learning (No abstract)\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x005AC7F3+24435]\n\t(No symbol) [0x00532074]\n\t(No symbol) [0x004006E3]\n\t(No symbol) [0x00448B39]\n\t(No symbol) [0x00448E8B]\n\t(No symbol) [0x00491AC2]\n\t(No symbol) [0x0046D804]\n\t(No symbol) [0x0048F20A]\n\t(No symbol) [0x0046D5B6]\n\t(No symbol) [0x0043C54F]\n\t(No symbol) [0x0043D894]\n\tGetHandleVerifier [0x008B70A3+3213347]\n\tGetHandleVerifier [0x008CB0C9+3295305]\n\tGetHandleVerifier [0x008C558C+3271948]\n\tGetHandleVerifier [0x00647360+658144]\n\t(No symbol) [0x0053B27D]\n\t(No symbol) [0x00538208]\n\t(No symbol) [0x005383A9]\n\t(No symbol) [0x0052AAC0]\n\tBaseThreadInitThunk [0x75875D49+25]\n\tRtlInitializeExceptionChain [0x7798CE3B+107]\n\tRtlGetAppContainerNamedObjectPath [0x7798CDC1+561]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your research topic: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m----> 2\u001b[0m final_paper \u001b[38;5;241m=\u001b[39m supervisor_agent(search_query)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸŽ¯ Best Retrieved Research Paper:\u001b[39m\u001b[38;5;124m\"\u001b[39m, final_paper)\n",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m, in \u001b[0;36msupervisor_agent\u001b[1;34m(search_query)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msupervisor_agent\u001b[39m(search_query):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ”¶ Supervisor Agent: Managing Research on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     papers \u001b[38;5;241m=\u001b[39m generation_agent(search_query)\n\u001b[0;32m      5\u001b[0m     feasible_papers \u001b[38;5;241m=\u001b[39m reflection_agent(papers, search_query)\n\u001b[0;32m      6\u001b[0m     ranked_papers \u001b[38;5;241m=\u001b[39m ranking_agent(feasible_papers)\n",
      "Cell \u001b[1;32mIn[75], line 65\u001b[0m, in \u001b[0;36mgeneration_agent\u001b[1;34m(search_query)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_papers):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# âœ… Fix: Fetch fresh elements dynamically in each loop iteration\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m         title_element \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     66\u001b[0m             EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mXPATH, details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_xpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     67\u001b[0m         )\n\u001b[0;32m     68\u001b[0m         link_element \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     69\u001b[0m             EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mXPATH, details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink_xpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     70\u001b[0m         )\n\u001b[0;32m     72\u001b[0m         title_text \u001b[38;5;241m=\u001b[39m title_element\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m title_element \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sinch\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:146\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n\tGetHandleVerifier [0x005AC7F3+24435]\n\t(No symbol) [0x00532074]\n\t(No symbol) [0x004006E3]\n\t(No symbol) [0x00448B39]\n\t(No symbol) [0x00448E8B]\n\t(No symbol) [0x00491AC2]\n\t(No symbol) [0x0046D804]\n\t(No symbol) [0x0048F20A]\n\t(No symbol) [0x0046D5B6]\n\t(No symbol) [0x0043C54F]\n\t(No symbol) [0x0043D894]\n\tGetHandleVerifier [0x008B70A3+3213347]\n\tGetHandleVerifier [0x008CB0C9+3295305]\n\tGetHandleVerifier [0x008C558C+3271948]\n\tGetHandleVerifier [0x00647360+658144]\n\t(No symbol) [0x0053B27D]\n\t(No symbol) [0x00538208]\n\t(No symbol) [0x005383A9]\n\t(No symbol) [0x0052AAC0]\n\tBaseThreadInitThunk [0x75875D49+25]\n\tRtlInitializeExceptionChain [0x7798CE3B+107]\n\tRtlGetAppContainerNamedObjectPath [0x7798CDC1+561]\n"
     ]
    }
   ],
   "source": [
    "search_query = input(\"Enter your research topic: \").strip()\n",
    "final_paper = supervisor_agent(search_query)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Best Retrieved Research Paper:\", final_paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
